{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae03cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "from __future__ import print_function\n",
    "\n",
    "from scipy.spatial import distance as dist\n",
    "import scipy.ndimage.filters as signal\n",
    "\n",
    "from imutils import face_utils\n",
    "\n",
    "import datetime\n",
    "import imutils\n",
    "import dlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "from tkinter import*\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import pickle\n",
    "from queue import Queue\n",
    "\n",
    "# import the necessary packages\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aef8e3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical feature extraction: Ghoddoosian, R., Galib, M., & Athitsos, V. (2019).\n",
    "# A Realistic Dataset and Baseline Temporal Model for Early Drowsiness Detection. \n",
    "# 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops \n",
    "#(CVPRW). https://doi.org/10.1109/cvprw.2019.00027)\n",
    "\n",
    "# Adjust_gamma from https://www.pyimagesearch.com/2015/10/05/opencv-gamma-correction/\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "                      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "def blink_detector(output_textfile,input_video):\n",
    "\n",
    "\n",
    "\n",
    "    Q = Queue(maxsize=7)\n",
    "\n",
    "    FRAME_MARGIN_BTW_2BLINKS=3\n",
    "    MIN_AMPLITUDE=0.04\n",
    "    MOUTH_AR_THRESH=0.35\n",
    "    MOUTH_AR_THRESH_ALERT=0.30\n",
    "    MOUTH_AR_CONSEC_FRAMES=20\n",
    "\n",
    "    EPSILON=0.01  # for discrete derivative (avoiding zero derivative)\n",
    "    class Blink():\n",
    "        def __init__(self):\n",
    "\n",
    "            self.start=0 #frame\n",
    "            self.startEAR=1\n",
    "            self.peak=0  #frame\n",
    "            self.peakEAR = 1\n",
    "            self.end=0   #frame\n",
    "            self.endEAR=0\n",
    "            self.amplitude=(self.startEAR+self.endEAR-2*self.peakEAR)/2\n",
    "            self.duration = self.end-self.start+1\n",
    "            self.EAR_of_FOI=0 #FrameOfInterest\n",
    "            self.values=[]\n",
    "            self.velocity=0  #Eye-closing velocity\n",
    "\n",
    "\n",
    "\n",
    "    def eye_aspect_ratio(eye):\n",
    "        # compute the euclidean distances between the two sets of\n",
    "        # vertical eye landmarks (x, y)-coordinates\n",
    "        A = dist.euclidean(eye[1], eye[5])\n",
    "        B = dist.euclidean(eye[2], eye[4])\n",
    "\n",
    "        # compute the euclidean distance between the horizontal\n",
    "        # eye landmark (x, y)-coordinates\n",
    "        C = dist.euclidean(eye[0], eye[3])\n",
    "\n",
    "        if C<0.1:           #practical finetuning due to possible numerical issue as a result of optical flow\n",
    "            ear=0.3\n",
    "        else:\n",
    "            # compute the eye aspect ratio\n",
    "            ear = (A + B) / (2.0 * C)\n",
    "        if ear>0.45:        #practical finetuning due to possible numerical issue as a result of optical flow\n",
    "            ear=0.45\n",
    "        # return the eye aspect ratio\n",
    "        return ear\n",
    "\n",
    "    def mouth_aspect_ratio(mouth):\n",
    "\n",
    "        A = dist.euclidean(mouth[14], mouth[18])\n",
    "\n",
    "        C = dist.euclidean(mouth[12], mouth[16])\n",
    "\n",
    "        if C<0.1:           #practical finetuning\n",
    "            mar=0.2\n",
    "        else:\n",
    "            # compute the mouth aspect ratio\n",
    "            mar = (A ) / (C)\n",
    "\n",
    "        # return the mouth aspect ratio\n",
    "        return mar\n",
    "\n",
    "\n",
    "    def EMERGENCY(ear, COUNTER):\n",
    "        if ear < 0.21:\n",
    "            COUNTER += 1\n",
    "\n",
    "            if COUNTER >= 50:\n",
    "                print('EMERGENCY SITUATION (EYES TOO LONG CLOSED)')\n",
    "                print(COUNTER)\n",
    "                COUNTER = 0\n",
    "        else:\n",
    "            COUNTER=0\n",
    "        return COUNTER\n",
    "\n",
    "    def Linear_Interpolate(start,end,N):\n",
    "        m=(end-start)/(N+1)\n",
    "        x=np.linspace(1,N,N)\n",
    "        y=m*(x-0)+start\n",
    "        return list(y)\n",
    "\n",
    "    def Ultimate_Blink_Check():\n",
    "        #Given the input \"values\", retrieve blinks and their quantities\n",
    "        retrieved_blinks=[]\n",
    "        MISSED_BLINKS=False\n",
    "        values=np.asarray(Last_Blink.values)\n",
    "        THRESHOLD=0.4*np.min(values)+0.6*np.max(values)   # this is to split extrema in highs and lows\n",
    "        N=len(values)\n",
    "        Derivative=values[1:N]-values[0:N-1]    #[-1 1] is used for derivative\n",
    "        i=np.where(Derivative==0)\n",
    "        if len(i[0])!=0:\n",
    "            for k in i[0]:\n",
    "                if k==0:\n",
    "                    Derivative[0]=-EPSILON\n",
    "                else:\n",
    "                    Derivative[k]=EPSILON*Derivative[k-1]\n",
    "        M=N-1    #len(Derivative)\n",
    "        ZeroCrossing=Derivative[1:M]*Derivative[0:M-1]\n",
    "        x = np.where(ZeroCrossing < 0)\n",
    "        xtrema_index=x[0]+1\n",
    "        XtremaEAR=values[xtrema_index]\n",
    "        Updown=np.ones(len(xtrema_index))        # 1 means high, -1 means low for each extremum\n",
    "        Updown[XtremaEAR<THRESHOLD]=-1           #this says if the extremum occurs in the upper/lower half of signal\n",
    "        #concatenate the beginning and end of the signal as positive high extrema\n",
    "        Updown=np.concatenate(([1],Updown,[1]))\n",
    "        XtremaEAR=np.concatenate(([values[0]],XtremaEAR,[values[N-1]]))\n",
    "        xtrema_index = np.concatenate(([0], xtrema_index,[N - 1]))\n",
    "        ##################################################################\n",
    "\n",
    "        Updown_XeroCrossing = Updown[1:len(Updown)] * Updown[0:len(Updown) - 1]\n",
    "        jump_index = np.where(Updown_XeroCrossing < 0)\n",
    "        numberOfblinks = int(len(jump_index[0]) / 2)\n",
    "        selected_EAR_First = XtremaEAR[jump_index[0]]\n",
    "        selected_EAR_Sec = XtremaEAR[jump_index[0] + 1]\n",
    "        selected_index_First = xtrema_index[jump_index[0]]\n",
    "        selected_index_Sec = xtrema_index[jump_index[0] + 1]\n",
    "        if numberOfblinks>1:\n",
    "            MISSED_BLINKS=True\n",
    "        if numberOfblinks ==0:\n",
    "            print(Updown,Last_Blink.duration)\n",
    "            print(values)\n",
    "            print(Derivative)\n",
    "        for j in range(numberOfblinks):\n",
    "            detected_blink=Blink()\n",
    "            detected_blink.start=selected_index_First[2*j]\n",
    "            detected_blink.peak = selected_index_Sec[2*j]\n",
    "            detected_blink.end = selected_index_Sec[2*j + 1]\n",
    "\n",
    "            detected_blink.startEAR=selected_EAR_First[2*j]\n",
    "            detected_blink.peakEAR = selected_EAR_Sec[2*j]\n",
    "            detected_blink.endEAR = selected_EAR_Sec[2*j + 1]\n",
    "\n",
    "            detected_blink.duration=detected_blink.end-detected_blink.start+1\n",
    "            detected_blink.amplitude=0.5*(detected_blink.startEAR-detected_blink.peakEAR)+0.5*(detected_blink.endEAR-detected_blink.peakEAR)\n",
    "            detected_blink.velocity=(detected_blink.endEAR-selected_EAR_First[2*j+1])/(detected_blink.end-selected_index_First[2*j+1]+1) #eye opening ave velocity\n",
    "            retrieved_blinks.append(detected_blink)\n",
    "\n",
    "\n",
    "\n",
    "        return MISSED_BLINKS,retrieved_blinks\n",
    "\n",
    "\n",
    "\n",
    "    def Blink_Tracker(EAR,IF_Closed_Eyes,Counter4blinks,TOTAL_BLINKS,skip):\n",
    "        BLINK_READY=False\n",
    "        #If the eyes are closed\n",
    "        if int(IF_Closed_Eyes)==1:\n",
    "            Current_Blink.values.append(EAR)\n",
    "            Current_Blink.EAR_of_FOI=EAR      #Save to use later\n",
    "            if Counter4blinks>0:\n",
    "                skip = False\n",
    "            if Counter4blinks==0:\n",
    "                Current_Blink.startEAR=EAR    #EAR_series[6] is the EAR for the frame of interest(the middle one)\n",
    "                Current_Blink.start=reference_frame-6   #reference-6 points to the frame of interest which will be the 'start' of the blink\n",
    "            Counter4blinks += 1\n",
    "            if Current_Blink.peakEAR>=EAR:    #deciding the min point of the EAR signal\n",
    "                Current_Blink.peakEAR =EAR\n",
    "                Current_Blink.peak=reference_frame-6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # otherwise, the eyes are open in this frame\n",
    "        else:\n",
    "\n",
    "            if Counter4blinks <2 and skip==False :           # Wait to approve or reject the last blink\n",
    "                if Last_Blink.duration>15:\n",
    "                    FRAME_MARGIN_BTW_2BLINKS=8\n",
    "                else:\n",
    "                    FRAME_MARGIN_BTW_2BLINKS=1\n",
    "                if ( (reference_frame-6) - Last_Blink.end) > FRAME_MARGIN_BTW_2BLINKS:\n",
    "                    # Check so the prev blink signal is not monotonic or too small (noise)\n",
    "                    if  Last_Blink.peakEAR < Last_Blink.startEAR and Last_Blink.peakEAR < Last_Blink.endEAR and Last_Blink.amplitude>MIN_AMPLITUDE and Last_Blink.start<Last_Blink.peak:\n",
    "                        if((Last_Blink.startEAR - Last_Blink.peakEAR)> (Last_Blink.endEAR - Last_Blink.peakEAR)*0.25 and (Last_Blink.startEAR - Last_Blink.peakEAR)*0.25< (Last_Blink.endEAR - Last_Blink.peakEAR)): # the amplitude is balanced\n",
    "                            BLINK_READY = True\n",
    "                            #####THE ULTIMATE BLINK Check\n",
    "\n",
    "                            Last_Blink.values=signal.convolve1d(Last_Blink.values, [1/3.0, 1/3.0,1/3.0],mode='nearest')\n",
    "                            # Last_Blink.values=signal.median_filter(Last_Blink.values, 3, mode='reflect')   # smoothing the signal\n",
    "                            [MISSED_BLINKS,retrieved_blinks]=Ultimate_Blink_Check()\n",
    "                            #####\n",
    "                            TOTAL_BLINKS =TOTAL_BLINKS+len(retrieved_blinks)  # Finally, approving/counting the previous blink candidate\n",
    "                            ###Now You can count on the info of the last separate and valid blink and analyze it\n",
    "                            Counter4blinks = 0\n",
    "                            print(\"MISSED BLINKS= {}\".format(len(retrieved_blinks)))\n",
    "                            return retrieved_blinks,int(TOTAL_BLINKS),Counter4blinks,BLINK_READY,skip\n",
    "                        else:\n",
    "                            skip=True\n",
    "                            print('rejected due to imbalance')\n",
    "                    else:\n",
    "                        skip = True\n",
    "                        print('rejected due to noise,magnitude is {}'.format(Last_Blink.amplitude))\n",
    "                        print(Last_Blink.start<Last_Blink.peak)\n",
    "\n",
    "            # if the eyes were closed for a sufficient number of frames (2 or more)\n",
    "            # then this is a valid CANDIDATE for a blink\n",
    "            if Counter4blinks >1:\n",
    "                Current_Blink.end = reference_frame - 7  #reference-7 points to the last frame that eyes were closed\n",
    "                Current_Blink.endEAR=Current_Blink.EAR_of_FOI\n",
    "                Current_Blink.amplitude = (Current_Blink.startEAR + Current_Blink.endEAR - 2 * Current_Blink.peakEAR) / 2\n",
    "                Current_Blink.duration = Current_Blink.end - Current_Blink.start + 1\n",
    "\n",
    "                if Last_Blink.duration>15:\n",
    "                    FRAME_MARGIN_BTW_2BLINKS=8\n",
    "                else:\n",
    "                    FRAME_MARGIN_BTW_2BLINKS=1\n",
    "                if (Current_Blink.start-Last_Blink.end )<=FRAME_MARGIN_BTW_2BLINKS+1:  #Merging two close blinks\n",
    "                    print('Merging...')\n",
    "                    frames_in_between=Current_Blink.start - Last_Blink.end-1\n",
    "                    print(Current_Blink.start ,Last_Blink.end, frames_in_between)\n",
    "                    valuesBTW=Linear_Interpolate(Last_Blink.endEAR,Current_Blink.startEAR,frames_in_between)\n",
    "                    Last_Blink.values=Last_Blink.values+valuesBTW+Current_Blink.values\n",
    "                    Last_Blink.end = Current_Blink.end            # update the end\n",
    "                    Last_Blink.endEAR = Current_Blink.endEAR\n",
    "                    if Last_Blink.peakEAR>Current_Blink.peakEAR:  #update the peak\n",
    "                        Last_Blink.peakEAR=Current_Blink.peakEAR\n",
    "                        Last_Blink.peak = Current_Blink.peak\n",
    "                        #update duration and amplitude\n",
    "                    Last_Blink.amplitude = (Last_Blink.startEAR + Last_Blink.endEAR - 2 * Last_Blink.peakEAR) / 2\n",
    "                    Last_Blink.duration = Last_Blink.end - Last_Blink.start + 1\n",
    "                else:                                             #Should not Merge (a Separate blink)\n",
    "\n",
    "                    Last_Blink.values=Current_Blink.values        #update the EAR list\n",
    "\n",
    "\n",
    "                    Last_Blink.end = Current_Blink.end            # update the end\n",
    "                    Last_Blink.endEAR = Current_Blink.endEAR\n",
    "\n",
    "                    Last_Blink.start = Current_Blink.start        #update the start\n",
    "                    Last_Blink.startEAR = Current_Blink.startEAR\n",
    "\n",
    "                    Last_Blink.peakEAR = Current_Blink.peakEAR    #update the peak\n",
    "                    Last_Blink.peak = Current_Blink.peak\n",
    "\n",
    "                    Last_Blink.amplitude = Current_Blink.amplitude\n",
    "                    Last_Blink.duration = Current_Blink.duration\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # reset the eye frame counter\n",
    "            Counter4blinks = 0\n",
    "        retrieved_blinks=0\n",
    "        return retrieved_blinks,int(TOTAL_BLINKS),Counter4blinks,BLINK_READY,skip\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('hello')\n",
    "    #\n",
    "\n",
    "\n",
    "    # initialize the frame counters and the total number of yawnings\n",
    "    COUNTER = 0\n",
    "    MCOUNTER=0\n",
    "    TOTAL = 0\n",
    "    MTOTAL=0\n",
    "    TOTAL_BLINKS=0\n",
    "    Counter4blinks=0\n",
    "    skip=False # to make sure a blink is not counted twice in the Blink_Tracker function\n",
    "    Last_Blink=Blink()\n",
    "\n",
    "    print(\"[INFO] loading facial landmark predictor...\")\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    #Load the Facial Landmark Detector\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "    #Load the Blink Detector\n",
    "    loaded_svm = pickle.load(open('Trained_SVM_C=1000_gamma=0.1_for 7kNegSample.sav', 'rb'))\n",
    "    # grab the indexes of the facial landmarks for the left and\n",
    "    # right eye, respectively\n",
    "    (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "    (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "    (mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "    print(\"[INFO] starting video stream thread...\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    lk_params=dict( winSize  = (13,13),\n",
    "                        maxLevel = 2,\n",
    "                        criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "    EAR_series=np.zeros([13])\n",
    "    Frame_series=np.linspace(1,13,13)\n",
    "    reference_frame=0\n",
    "    First_frame=True\n",
    "    top = tk.Tk()\n",
    "    frame1 = Frame(top)\n",
    "    frame1.grid(row=0, column=0)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plot_frame =FigureCanvasTkAgg(fig, master=frame1)\n",
    "    plot_frame.get_tk_widget().pack(side=tk.BOTTOM, expand=True)\n",
    "    plt.ylim([0.0, 0.5])\n",
    "    line, = ax.plot(Frame_series,EAR_series)\n",
    "    plot_frame.draw()\n",
    "\n",
    "    # loop over frames from the video stream\n",
    "\n",
    "\n",
    "    stream = cv2.VideoCapture(path)\n",
    "    start = datetime.datetime.now()\n",
    "    number_of_frames=0\n",
    "    while True:\n",
    "        (grabbed, frame) = stream.read()\n",
    "        if not grabbed:\n",
    "            print('not grabbed')\n",
    "            print(number_of_frames)\n",
    "            break\n",
    "\n",
    "\n",
    "        frame = imutils.resize(frame, width=450)\n",
    "\n",
    "        # To Rotate by 90 degreees\n",
    "        # rows=np.shape(frame)[0]\n",
    "        # cols = np.shape(frame)[1]\n",
    "        # M = cv2.getRotationMatrix2D((cols / 2, rows / 2),-90, 1)\n",
    "        # frame = cv2.warpAffine(frame, M, (cols, rows))\n",
    "\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)   #Brighten the image(Gamma correction)\n",
    "        reference_frame = reference_frame + 1\n",
    "        gray=adjust_gamma(gray,gamma=1.5)\n",
    "        Q.put(frame)\n",
    "        end = datetime.datetime.now()\n",
    "        ElapsedTime=(end - start).total_seconds()\n",
    "\n",
    "\n",
    "\n",
    "        # detect faces in the grayscale frame\n",
    "        rects = detector(gray, 0)\n",
    "        if (np.size(rects) != 0):\n",
    "            number_of_frames = number_of_frames + 1  # we only consider frames that face is detected\n",
    "            First_frame = False\n",
    "            old_gray = gray.copy()\n",
    "            # determine the facial landmarks for the face region, then\n",
    "            # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "            # array\n",
    "            shape = predictor(gray, rects[0])\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "            ###############YAWNING##################\n",
    "            #######################################\n",
    "            Mouth = shape[mStart:mEnd]\n",
    "            MAR = mouth_aspect_ratio(Mouth)\n",
    "\n",
    "\n",
    "            MouthHull = cv2.convexHull(Mouth)\n",
    "            cv2.drawContours(frame, [MouthHull], -1, (255, 0, 0), 1)\n",
    "\n",
    "            if MAR > MOUTH_AR_THRESH:\n",
    "               MCOUNTER += 1\n",
    "\n",
    "            elif MAR < MOUTH_AR_THRESH_ALERT:\n",
    "\n",
    "                if MCOUNTER >= MOUTH_AR_CONSEC_FRAMES:\n",
    "                    MTOTAL += 1\n",
    "\n",
    "                MCOUNTER = 0\n",
    "\n",
    "\n",
    "            ##############YAWNING####################\n",
    "            #########################################\n",
    "\n",
    "            # extract the left and right eye coordinates, then use the\n",
    "            # coordinates to compute the eye aspect ratio for both eyes\n",
    "\n",
    "            leftEye = shape[lStart:lEnd]\n",
    "            rightEye = shape[rStart:rEnd]\n",
    "            leftEAR = eye_aspect_ratio(leftEye)\n",
    "            rightEAR = eye_aspect_ratio(rightEye)\n",
    "\n",
    "            # average the eye aspect ratio together for both eyes\n",
    "            ear = (leftEAR + rightEAR) / 2.0\n",
    "            #EAR_series[reference_frame]=ear\n",
    "            EAR_series = shift(EAR_series, -1, cval=ear)\n",
    "\n",
    "            # compute the convex hull for the left and right eye, then\n",
    "            # visualize each of the eyes\n",
    "            leftEyeHull = cv2.convexHull(leftEye)\n",
    "            rightEyeHull = cv2.convexHull(rightEye)\n",
    "            cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "\n",
    "            ############HANDLING THE EMERGENCY SITATION################\n",
    "            ###########################################################\n",
    "            ###########################################################\n",
    "            COUNTER=EMERGENCY(ear,COUNTER)\n",
    "\n",
    "             # EMERGENCY SITUATION (EYES TOO LONG CLOSED) ALERT THE DRIVER IMMEDIATELY\n",
    "            ############HANDLING THE EMERGENCY SITATION################\n",
    "            ###########################################################\n",
    "            ###########################################################\n",
    "\n",
    "            if Q.full() and (reference_frame>15):  #to make sure the frame of interest for the EAR vector is int the mid\n",
    "                EAR_table = EAR_series\n",
    "                IF_Closed_Eyes = loaded_svm.predict(EAR_series.reshape(1,-1))\n",
    "                if Counter4blinks==0:\n",
    "                    Current_Blink = Blink()\n",
    "                retrieved_blinks, TOTAL_BLINKS, Counter4blinks, BLINK_READY, skip = Blink_Tracker(EAR_series[6],\n",
    "                                                                                                      IF_Closed_Eyes,\n",
    "                                                                                                      Counter4blinks,\n",
    "                                                                                                      TOTAL_BLINKS, skip)\n",
    "                if (BLINK_READY==True):\n",
    "                    reference_frame=20   #initialize to a random number to avoid overflow in large numbers\n",
    "                    skip = True\n",
    "                    #####\n",
    "                    BLINK_FRAME_FREQ = TOTAL_BLINKS / number_of_frames\n",
    "                    for detected_blink in retrieved_blinks:\n",
    "                        print(detected_blink.amplitude, Last_Blink.amplitude)\n",
    "                        print(detected_blink.duration, detected_blink.velocity)\n",
    "                        print(number_of_frames)\n",
    "                        print('-------------------')\n",
    "\n",
    "                        if(detected_blink.velocity>0):\n",
    "                          with open(output_file, 'ab') as f_handle:\n",
    "                             f_handle.write(b'\\n')\n",
    "                             np.savetxt(f_handle,[number_of_frames,TOTAL_BLINKS,BLINK_FRAME_FREQ*100,detected_blink.amplitude,detected_blink.duration,detected_blink.velocity], delimiter=', ', newline=' ',fmt='%.4f')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    Last_Blink.end = -10 # re initialization\n",
    "                    #####\n",
    "\n",
    "                line.set_ydata(EAR_series)\n",
    "                plot_frame.draw()\n",
    "                frameMinus7=Q.get()\n",
    "                cv2.imshow(\"Frame\", frameMinus7)\n",
    "            elif Q.full():         #just to make way for the new input of the Q when the Q is full\n",
    "                junk =  Q.get()\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            # if the `q` key was pressed, break from the loop\n",
    "            if key != 0xFF:\n",
    "                break\n",
    "        #Does not detect any face\n",
    "        else:\n",
    "            ###################Using Optical Flow############\n",
    "            ###################    (Optional)    ############\n",
    "            st=0\n",
    "            st2=0\n",
    "            if (First_frame == False):\n",
    "                leftEye=leftEye.astype(np.float32)\n",
    "                rightEye = rightEye.astype(np.float32)\n",
    "                p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, gray,leftEye, None, **lk_params)\n",
    "                p2, st2, err2 = cv2.calcOpticalFlowPyrLK(old_gray, gray, rightEye, None, **lk_params)\n",
    "\n",
    "            if np.sum(st)+np.sum(st2)==12 and First_frame==False:\n",
    "\n",
    "                p1 = np.round(p1).astype(np.int)\n",
    "                p2 = np.round(p2).astype(np.int)\n",
    "                #print(p1)\n",
    "\n",
    "                leftEAR = eye_aspect_ratio(p1)\n",
    "                rightEAR = eye_aspect_ratio(p2)\n",
    "\n",
    "                ear = (leftEAR + rightEAR) / 2.0\n",
    "                EAR_series = shift(EAR_series, -1, cval=ear)\n",
    "                #EAR_series[reference_frame] = ear\n",
    "                leftEyeHull = cv2.convexHull(p1)\n",
    "                rightEyeHull = cv2.convexHull(p2)\n",
    "                cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "                cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "                old_gray = gray.copy()\n",
    "                leftEye = p1\n",
    "                rightEye = p2\n",
    "                ############HANDLING THE EMERGENCY SITATION################\n",
    "                ###########################################################\n",
    "                ###########################################################\n",
    "                COUNTER = EMERGENCY(ear, COUNTER)\n",
    "                ############HANDLING THE EMERGENCY SITATION################\n",
    "                ###########################################################\n",
    "                ###########################################################\n",
    "\n",
    "\n",
    "            ###################Using Optical Flow############\n",
    "            ###################                  ############\n",
    "\n",
    "            if Q.full() and (reference_frame>15):\n",
    "                EAR_table = EAR_series\n",
    "                IF_Closed_Eyes = loaded_svm.predict(EAR_series.reshape(1,-1))\n",
    "                if Counter4blinks==0:\n",
    "                    Current_Blink = Blink()\n",
    "                    retrieved_blinks, TOTAL_BLINKS, Counter4blinks, BLINK_READY, skip = Blink_Tracker(EAR_series[6],\n",
    "                                                                                                      IF_Closed_Eyes,\n",
    "                                                                                                      Counter4blinks,\n",
    "                                                                                                      TOTAL_BLINKS, skip)\n",
    "                if (BLINK_READY==True):\n",
    "                    reference_frame=20   #initialize to a random number to avoid overflow in large numbers\n",
    "                    skip = True\n",
    "                    #####\n",
    "                    BLINK_FRAME_FREQ = TOTAL_BLINKS / number_of_frames\n",
    "                    for detected_blink in retrieved_blinks:\n",
    "                        print(detected_blink.amplitude, Last_Blink.amplitude)\n",
    "                        print(detected_blink.duration, Last_Blink.duration)\n",
    "                        print(number_of_frames)\n",
    "                        print('-------------------')\n",
    "                        with open(output_file, 'ab') as f_handle:\n",
    "                            f_handle.write(b'\\n')\n",
    "                            np.savetxt(f_handle,[number_of_frames,TOTAL_BLINKS,BLINK_FRAME_FREQ*100,detected_blink.amplitude,detected_blink.duration,detected_blink.velocity], delimiter=', ', newline=' ',fmt='%.4f')\n",
    "\n",
    "                    Last_Blink.end = -10 # re initialization\n",
    "\n",
    "\n",
    "                    #####\n",
    "\n",
    "                line.set_ydata(EAR_series)\n",
    "                plot_frame.draw()\n",
    "                frameMinus7=Q.get()\n",
    "                cv2.imshow(\"Frame\", frameMinus7)\n",
    "            elif Q.full():\n",
    "                junk = Q.get()\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\n",
    "            if key != 0xFF:\n",
    "                 break\n",
    "\n",
    "    # do a bit of cleanup\n",
    "    stream.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ea7b709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0S34.txt\n",
      "hello\n",
      "[INFO] loading facial landmark predictor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pnanp\\anaconda3\\envs\\Fontys_Minor_PA\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\pnanp\\anaconda3\\envs\\Fontys_Minor_PA\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\pnanp\\anaconda3\\envs\\Fontys_Minor_PA\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\pnanp\\anaconda3\\envs\\Fontys_Minor_PA\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\Users\\pnanp\\anaconda3\\envs\\Fontys_Minor_PA\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1074: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=1, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\pnanp\\anaconda3\\envs\\Fontys_Minor_PA\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1306: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=1, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\pnanp\\anaconda3\\envs\\Fontys_Minor_PA\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1442: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "C:\\Users\\pnanp\\anaconda3\\envs\\Fontys_Minor_PA\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\pnanp\\anaconda3\\envs\\Fontys_Minor_PA\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:318: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "C:\\Users\\pnanp\\anaconda3\\envs\\Fontys_Minor_PA\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:575: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=1,\n",
      "C:\\Users\\pnanp\\anaconda3\\envs\\Fontys_Minor_PA\\lib\\site-packages\\sklearn\\base.py:311: UserWarning: Trying to unpickle estimator SVC from version pre-0.18 when using version 0.19.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream thread...\n",
      "rejected due to noise,magnitude is -0.5\n",
      "False\n",
      "0s37.txt\n",
      "hello\n",
      "[INFO] loading facial landmark predictor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pnanp\\anaconda3\\envs\\Fontys_Minor_PA\\lib\\site-packages\\sklearn\\base.py:311: UserWarning: Trying to unpickle estimator SVC from version pre-0.18 when using version 0.19.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream thread...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_38384\\573514744.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# the path to the input video\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mblink_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_38384\\169655087.py\u001b[0m in \u001b[0;36mblink_detector\u001b[1;34m(output_textfile, input_video)\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[0mreference_frame\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[0mFirst_frame\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m     \u001b[0mtop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m     \u001b[0mframe1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[0mframe1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Fontys_Minor_PA\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[0;32m   2023\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msync\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2024\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2025\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2026\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_environment\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2027\u001b[0m             \u001b[1;31m# Issue #16248: Honor the -E flag to avoid code injection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Fontys_Minor_PA\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36m_loadtk\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2055\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_support_default_root\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_default_root\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2056\u001b[0m             \u001b[0m_default_root\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2057\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"WM_DELETE_WINDOW\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2058\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdestroy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2059\u001b[0m         \"\"\"Destroy this and all descendants widgets. This will\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Fontys_Minor_PA\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36mwm_protocol\u001b[1;34m(self, name, func)\u001b[0m\n\u001b[0;32m   1959\u001b[0m         e.g. \"WM_SAVE_YOURSELF\" or \"WM_DELETE_WINDOW\".\"\"\"\n\u001b[0;32m   1960\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1961\u001b[1;33m             \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_register\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1962\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Fontys_Minor_PA\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36m_register\u001b[1;34m(self, func, subst, needcleanup)\u001b[0m\n\u001b[0;32m   1370\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1372\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreatecommand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1373\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mneedcleanup\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tclCommands\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Applying extraction and storing the result\n",
    "\n",
    "dir = r'C:\\Users\\pnanp\\Desktop\\Minor.AI4S.S6\\Personal Project\\Data\\Fold1_part1'\n",
    "for file in os.listdir(dir):\n",
    "    output_file = file.split('.')[0] + '.txt'  # The text file to write to (for blinks)\n",
    "    print(output_file)\n",
    "    path=os.path.join(dir, file) # the path to the input video\n",
    "    blink_detector(output_file,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b873b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fontys_Minor_PA",
   "language": "python",
   "name": "fontys_minor_pa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
