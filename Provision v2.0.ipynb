{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8054f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils.video import FileVideoStream\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6622862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    # Vertical\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])  \n",
    "    # Horizontal\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    # EAR\n",
    "    ear = (A + B)/(2.0 * C)\n",
    "    \n",
    "    return ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d876a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1809b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "860ce6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = pd.read_csv(r'C:\\Users\\pnanp\\Desktop\\Minor.AI4S.S6\\Personal Project\\threshf3p1.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7013a406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating 0s26.mp4\n",
      "0s26.mp4 features extracted\n",
      "Data updated to 40 rows\n",
      "----------------------------------------\n",
      "Initiating 0s27.mp4\n",
      "0s27.mp4 features extracted\n",
      "Data updated to 104 rows\n",
      "----------------------------------------\n",
      "Initiating 0s28.mp4\n",
      "0s28.mp4 features extracted\n",
      "Data updated to 171 rows\n",
      "----------------------------------------\n",
      "Initiating 0s29.mp4\n",
      "0s29.mp4 features extracted\n",
      "Data updated to 234 rows\n",
      "----------------------------------------\n",
      "Initiating 0s30.mp4\n",
      "0s30.mp4 features extracted\n",
      "Data updated to 309 rows\n",
      "----------------------------------------\n",
      "Initiating 10s26.mp4\n",
      "10s26.mp4 features extracted\n",
      "Data updated to 373 rows\n",
      "----------------------------------------\n",
      "Initiating 10s27.mp4\n",
      "10s27.mp4 features extracted\n",
      "Data updated to 467 rows\n",
      "----------------------------------------\n",
      "Initiating 10s28.mp4\n",
      "10s28.mp4 features extracted\n",
      "Data updated to 516 rows\n",
      "----------------------------------------\n",
      "Initiating 10s29.mp4\n",
      "10s29.mp4 features extracted\n",
      "Data updated to 623 rows\n",
      "----------------------------------------\n",
      "Initiating 10s30.mp4\n",
      "10s30.mp4 features extracted\n",
      "Data updated to 716 rows\n",
      "----------------------------------------\n",
      "Initiating 5s26.mp4\n",
      "5s26.mp4 features extracted\n",
      "Data updated to 838 rows\n",
      "----------------------------------------\n",
      "Initiating 5s27.mp4\n",
      "5s27.mp4 features extracted\n",
      "Data updated to 903 rows\n",
      "----------------------------------------\n",
      "Initiating 5s28.mp4\n",
      "5s28.mp4 features extracted\n",
      "Data updated to 935 rows\n",
      "----------------------------------------\n",
      "Initiating 5s29.mp4\n",
      "5s29.mp4 features extracted\n",
      "Data updated to 1025 rows\n",
      "----------------------------------------\n",
      "Initiating 5s30.mp4\n",
      "5s30.mp4 features extracted\n",
      "Data updated to 1098 rows\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ATTRIBUTE DERIVATION\n",
    "\n",
    "data = pd.DataFrame()\n",
    "dir = r'C:\\Users\\pnanp\\Desktop\\Minor.AI4S.S6\\Personal Project\\Data\\Fold3_part1'\n",
    "\n",
    "# Looping through directory for mp4 files to read\n",
    "for file in os.listdir(dir):\n",
    "    if file.endswith(\".mp4\"):\n",
    "        path=os.path.join(dir, file)\n",
    "        print('Initiating {}'.format(file))\n",
    "        \n",
    "        # Setting thresholds\n",
    "        avgEarThresh = thresh.loc[thresh.index[thresh.State == file]].iloc[0,0]\n",
    "        eyeThresh = (avgEarThresh*90)/100\n",
    "        consecFrameThresh = 3\n",
    "        \n",
    "        # Setting counters\n",
    "        blinkCount = 0\n",
    "        blinkFrameCounter = 0\n",
    "        frameCount = 0\n",
    "        plinkFrameCounter = 0\n",
    "        eyeCloseFrame = 0\n",
    "        \n",
    "        # Defining lists to store attributes\n",
    "        allEars = []\n",
    "        Duration = []\n",
    "        Amplitude = []\n",
    "        Frequency = []\n",
    "        Frame = []\n",
    "        PERCLOS = []\n",
    "        \n",
    "        # Read the video\n",
    "        vs = FileVideoStream(path)\n",
    "        vs.start()\n",
    "        time.sleep(1.0)\n",
    "        \n",
    "        # While frame is incoming, read the frame\n",
    "        while vs.more() == True:  \n",
    "            frame = vs.read()\n",
    "            # If the frame is not of type None, perform adjustments and face detection\n",
    "            if vs.more() == True:\n",
    "                frame =  imutils.resize(frame, width=450)\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                frameCount += 1     # Count and track each frame\n",
    "\n",
    "                rects = detector(gray, 0)\n",
    "                \n",
    "                for rect in rects:\n",
    "                    # Predict the landmarks and convert their coordinates into an array\n",
    "                    shape =  predictor(gray, rect)\n",
    "                    shape = face_utils.shape_to_np(shape)\n",
    "                    # Extract the coordinates of left and right eyesusing the indexes derived before\n",
    "                    leftEye = shape[lStart:lEnd]\n",
    "                    rightEye = shape[rStart:rEnd]\n",
    "                    # Calculate EARs and take average\n",
    "                    leftEAR = eye_aspect_ratio(leftEye)\n",
    "                    rightEAR = eye_aspect_ratio(rightEye)\n",
    "\n",
    "                    ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "                    allEars.append(ear)     # List to track all EARs\n",
    "                    \n",
    "                    # Check threshold and current EAR\n",
    "                    if ear < eyeThresh:\n",
    "                        plinkFrameCounter += 1     # potential blink frame counter\n",
    "                        plinkEars.append(ear)      # List containing all EAR of closed eyes duration\n",
    "                    # The instance that EAR comes above the threshold   \n",
    "                    else:    \n",
    "                        # Check duration potential blink against frame threshold\n",
    "                        if plinkFrameCounter >= consecFrameThresh:\n",
    "                            blinkCount += 1\n",
    "                            eyeCloseFrame = eyeCloseFrame + plinkFrameCounter\n",
    "\n",
    "                            bottomEar = min(plinkEars)    # Lowest EAR is the min from the tracked list\n",
    "\n",
    "                            if max(allEars[-6:]) > eyeThresh:\n",
    "                                startEar = max(allEars[-6:])\n",
    "                            else:\n",
    "                                j = 7\n",
    "                                while max(allEars[-j:]) <= eyeThresh:\n",
    "                                    j += 1\n",
    "                                startEar = max(allEars[-(j+3):])\n",
    "\n",
    "                            duration = plinkFrameCounter\n",
    "                            Duration.append(duration)\n",
    "\n",
    "                            frequency = blinkCount/frameCount\n",
    "                            Frequency.append(frequency)\n",
    "                            Frame.append(frameCount)\n",
    "\n",
    "                            amplitude = startEar - bottomEar\n",
    "                            Amplitude.append(amplitude)\n",
    "                            \n",
    "                            perclos = 100*eyeCloseFrame/frameCount\n",
    "                            PERCLOS.append(perclos)\n",
    "                            \n",
    "                        # Resetting potential blink counter and EAR list\n",
    "                        plinkFrameCounter = 0\n",
    "                        plinkEars = []\n",
    "                    \n",
    "        print('{} features extracted'.format(file))\n",
    "        vs.stop()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        # Creating and extending dataframe\n",
    "        mediumDf = pd.DataFrame({'Duration': Duration, 'Amplitude': Amplitude, \n",
    "                                 'Frequency': Frequency, 'State': file, 'PERCLOS':PERCLOS})\n",
    "        data = data.append(mediumDf, ignore_index = True)\n",
    "        print('Data updated to {} rows'.format(len(data)))\n",
    "        print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce55136e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>State</th>\n",
       "      <th>PERCLOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.080071</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>0s26.mp4</td>\n",
       "      <td>2.453988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.049686</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0s26.mp4</td>\n",
       "      <td>1.014493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.094133</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0s26.mp4</td>\n",
       "      <td>1.381215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>0.171738</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0s26.mp4</td>\n",
       "      <td>3.017241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.045268</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0s26.mp4</td>\n",
       "      <td>3.326180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Duration  Amplitude  Frequency     State   PERCLOS\n",
       "0         4   0.080071   0.006135  0s26.mp4  2.453988\n",
       "1         3   0.049686   0.002899  0s26.mp4  1.014493\n",
       "2         3   0.094133   0.004144  0s26.mp4  1.381215\n",
       "3        18   0.171738   0.004310  0s26.mp4  3.017241\n",
       "4         3   0.045268   0.005365  0s26.mp4  3.326180"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() # Top rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39c1a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('f3p1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cc7d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
